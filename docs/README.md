# TP 2 : K-means Clustering 

---

## ğŸ“ Structure du Projet

```
votre_projet/
â”‚
â”œâ”€â”€ data/                                      # ğŸ“‚ DonnÃ©es sources
â”‚   â””â”€â”€ ObesityDataSet_raw_and_data_sinthetic.csv
â”‚
â”œâ”€â”€ resultats/                                 # ğŸ“‚ Tous les rÃ©sultats
â”‚   â”œâ”€â”€ visualisations/                        # ğŸ–¼ï¸ Graphiques PNG
â”‚   â”‚   â”œâ”€â”€ distribution_variable_cible.png
â”‚   â”‚   â”œâ”€â”€ distributions_numeriques.png
â”‚   â”‚   â”œâ”€â”€ matrice_correlation.png
â”‚   â”‚   â”œâ”€â”€ methode_coude.png
â”‚   â”‚   â”œâ”€â”€ score_silhouette.png
â”‚   â”‚   â”œâ”€â”€ davies_bouldin.png
â”‚   â”‚   â”œâ”€â”€ distribution_clusters.png
â”‚   â”‚   â”œâ”€â”€ matrice_confusion.png
â”‚   â”‚   â”œâ”€â”€ profils_clusters_heatmap.png
â”‚   â”‚   â”œâ”€â”€ pca_2d.png
â”‚   â”‚   â””â”€â”€ tsne_2d.png
â”‚   â”‚
â”‚   â”œâ”€â”€ obesity_with_clusters.csv             # ğŸ“Š Dataset avec clusters
â”‚   â”œâ”€â”€ profils_clusters.csv                  # ğŸ“Š Profils moyens
â”‚   â””â”€â”€ cluster_profiles_report.txt           # ğŸ“„ Rapport dÃ©taillÃ©
â”‚
â””â”€â”€ TP2_KMeans_Obesite_OPTIMISE.ipynb         # ğŸ““ Ce notebook
```

---

## ğŸš€ Installation Rapide

### 1ï¸âƒ£ CrÃ©er la structure

```bash
# CrÃ©er les dossiers (ou le notebook le fera automatiquement)
mkdir -p data resultats/visualisations
```

### 2ï¸âƒ£ Placer le dataset

TÃ©lÃ©chargez le fichier CSV et placez-le dans le dossier `data/` :

```
data/
â””â”€â”€ ObesityDataSet_raw_and_data_sinthetic.csv
```

### 3ï¸âƒ£ Installer les dÃ©pendances

```bash
pip install pandas numpy scikit-learn matplotlib seaborn jupyter
```

### 4ï¸âƒ£ Lancer le notebook

```bash
jupyter notebook TP2_KMeans_Obesite_OPTIMISE.ipynb
```

### 5ï¸âƒ£ ExÃ©cuter

- ExÃ©cutez toutes les cellules : `Cell â†’ Run All`
- Ou cellule par cellule : `Shift + Enter`

---

## ğŸ¯ AmÃ©liorations par Rapport Ã  la Version PrÃ©cÃ©dente

### ğŸ—‚ï¸ Organisation

| Avant | AprÃ¨s |
|-------|-------|
| Fichiers dans le dossier courant | Structure en dossiers claire |
| Graphiques non sauvegardÃ©s | Tous les graphiques exportÃ©s en PNG |
| Pas de rapport automatique | Rapport TXT dÃ©taillÃ© gÃ©nÃ©rÃ© |

### ğŸ’» Code

| Avant | AprÃ¨s |
|-------|-------|
| Chemins en dur | Utilisation de `pathlib.Path` |
| `random_state` rÃ©pÃ©tÃ© | Constante `RANDOM_STATE = 42` |
| Pas de vÃ©rification fichier | VÃ©rification avec message d'erreur clair |
| Commentaires techniques | Commentaires naturels et pÃ©dagogiques |

### ğŸ“Š Visualisations

| Avant | AprÃ¨s |
|-------|-------|
| Affichage uniquement | Sauvegarde automatique (DPI 150) |
| Pas de rÃ©capitulatif | Liste des fichiers gÃ©nÃ©rÃ©s |
| Graphiques basiques | Graphiques amÃ©liorÃ©s (annotations, grille) |

### ğŸ“ Rapports

| Avant | AprÃ¨s |
|-------|-------|
| Rapport simple | Rapport complet avec timestamp |
| Pas de rÃ©sumÃ© fichiers | RÃ©sumÃ© automatique avec tailles |
| CSV basique | CSV + profils moyens sÃ©parÃ©s |

---

## ğŸ“š Sections du Notebook

### 1. Configuration (Nouveau âœ¨)
- Import des bibliothÃ¨ques
- CrÃ©ation automatique des dossiers
- Configuration des constantes globales

### 2. Chargement des DonnÃ©es
- VÃ©rification de l'existence du fichier
- Message d'erreur clair si fichier manquant
- Exploration initiale complÃ¨te

### 3. PrÃ©traitement
- Encodage des variables catÃ©gorielles
- Normalisation StandardScaler
- Validation des transformations

### 4. DÃ©termination du K Optimal
- MÃ©thode du coude
- Score de silhouette
- Indice de Davies-Bouldin
- **Nouveau** : Sauvegarde automatique de chaque graphique

### 5. EntraÃ®nement K-means
- Configuration optimale
- Distribution des clusters
- Visualisation sauvegardÃ©e

### 6. Ã‰valuation
- MÃ©triques multiples
- InterprÃ©tation automatique (Nouveau âœ¨)
- Matrice de confusion sauvegardÃ©e

### 7. Analyse des Clusters
- Profils moyens exportÃ©s en CSV
- Heatmap des profils normalisÃ©s
- CaractÃ©risation textuelle dÃ©taillÃ©e

### 8. Visualisations AvancÃ©es
- PCA 2D avec centroÃ¯des
- t-SNE 2D
- **Nouveau** : Toutes sauvegardÃ©es automatiquement

### 9. Sauvegarde (AmÃ©liorÃ© âœ¨)
- Dataset enrichi
- Rapport complet avec timestamp
- RÃ©sumÃ© des fichiers gÃ©nÃ©rÃ©s

### 10. SynthÃ¨se Finale (Nouveau âœ¨)
- Configuration rÃ©capitulative
- MÃ©triques de performance
- Liste des livrables

---

## ğŸ¨ QualitÃ© du Code

### Conventions RespectÃ©es

âœ… **PEP 8** - Style Python standard  
âœ… **Noms explicites** - Variables claires (`K_OPTIMAL`, `RESULTS_DIR`)  
âœ… **Commentaires** - Explications naturelles  
âœ… **Organisation** - Sections logiques et progressives  
âœ… **ReproductibilitÃ©** - `RANDOM_STATE` utilisÃ© partout  
âœ… **Robustesse** - VÃ©rification des erreurs  

### Formatage

- **Constantes** : `MAJUSCULES_AVEC_UNDERSCORES`
- **Variables** : `snake_case_descriptif`
- **Spacing** : Lignes vides pour la lisibilitÃ©
- **Docstrings** : Markdown pour la documentation

---

## ğŸ“Š RÃ©sultats Attendus

Ã€ la fin de l'exÃ©cution, vous obtiendrez :

### Fichiers CSV (3)
- `obesity_with_clusters.csv` - Dataset original + colonne Cluster
- `profils_clusters.csv` - Moyennes par cluster
- (Le dataset original reste intact dans `data/`)

### Visualisations PNG (11+)
Tous les graphiques en haute rÃ©solution (150 DPI) :
- Distribution de la variable cible
- Distributions des variables numÃ©riques
- Matrice de corrÃ©lation
- MÃ©thode du coude
- Score de silhouette
- Davies-Bouldin
- Distribution des clusters
- Matrice de confusion
- Heatmap des profils
- PCA 2D
- t-SNE 2D

### Rapports (1)
- `cluster_profiles_report.txt` - Rapport complet avec :
  - Configuration du modÃ¨le
  - MÃ©triques de performance
  - Profils dÃ©taillÃ©s de chaque cluster
  - Timestamp

---

## â±ï¸ Temps d'ExÃ©cution

| Section | Temps EstimÃ© |
|---------|--------------|
| Configuration | < 1 sec |
| Chargement donnÃ©es | < 5 sec |
| PrÃ©traitement | < 5 sec |
| DÃ©termination K | ~3 min |
| EntraÃ®nement | < 30 sec |
| Ã‰valuation | < 10 sec |
| Analyse | < 30 sec |
| PCA | < 10 sec |
| t-SNE | 1-2 min |
| Sauvegarde | < 10 sec |
| **TOTAL** | **~6 minutes** |

---

## ğŸ”§ Configuration AvancÃ©e

### Modifier le Nombre de Clusters

```python
# AprÃ¨s la section 4.4, vous pouvez forcer un K spÃ©cifique
K_OPTIMAL = 7  # Par exemple pour comparer aux 7 catÃ©gories originales
```

### Changer les Dossiers

```python
# Section 1, cellule 2
DATA_DIR = Path('mes_donnees')
RESULTS_DIR = Path('mes_resultats')
```

### Ajuster les ParamÃ¨tres K-means

```python
# Section 5
kmeans_final = KMeans(
    n_clusters=K_OPTIMAL,
    init='k-means++',    # Ou 'random'
    n_init=20,           # Augmenter pour plus de stabilitÃ©
    max_iter=500,        # Augmenter si non convergence
    random_state=RANDOM_STATE
)
```

### Modifier la RÃ©solution des Images

```python
# Dans chaque plt.savefig()
plt.savefig(fichier, dpi=300, bbox_inches='tight')  # Haute rÃ©solution
```

---

## â“ FAQ

### Q : Puis-je utiliser mes propres donnÃ©es ?
**R :** Oui ! Placez votre CSV dans `data/` et modifiez `DATA_FILE` en consÃ©quence.

### Q : Les graphiques sont-ils modifiables ?
**R :** Oui ! Ils sont en format PNG. Vous pouvez aussi les regÃ©nÃ©rer avec d'autres paramÃ¨tres.

### Q : Comment changer le K optimal ?
**R :** Modifiez `K_OPTIMAL` aprÃ¨s la section 4.4 et rÃ©exÃ©cutez Ã  partir de la section 5.

### Q : Le notebook crÃ©e-t-il les dossiers automatiquement ?
**R :** Oui ! Si `data/` et `resultats/` n'existent pas, ils seront crÃ©Ã©s automatiquement.

### Q : Puis-je dÃ©sactiver la sauvegarde des graphiques ?
**R :** Oui, commentez les lignes `plt.savefig()` dans chaque cellule de visualisation.

---

## ğŸ“ Pour Aller Plus Loin

### Algorithmes Alternatifs
```python
from sklearn.cluster import DBSCAN, AgglomerativeClustering

# DBSCAN
dbscan = DBSCAN(eps=0.5, min_samples=5)
labels_dbscan = dbscan.fit_predict(X_scaled)

# Hierarchical
hierarchical = AgglomerativeClustering(n_clusters=K_OPTIMAL)
labels_hier = hierarchical.fit_predict(X_scaled)
```

### Feature Engineering
```python
# CrÃ©er l'IMC (Indice de Masse Corporelle)
df['IMC'] = df['Weight'] / (df['Height'] ** 2)

# Ratio activitÃ© / calories
df['Ratio_Sante'] = df['FAF'] / (df['FAVC'].map({'yes': 1, 'no': 0}) + 1)
```

### Validation CroisÃ©e
```python
from sklearn.model_selection import cross_val_score

# Tester la stabilitÃ© avec diffÃ©rentes graines
scores = []
for seed in range(10):
    kmeans = KMeans(n_clusters=K_OPTIMAL, random_state=seed)
    labels = kmeans.fit_predict(X_scaled)
    score = silhouette_score(X_scaled, labels)
    scores.append(score)
    
print(f"Score moyen : {np.mean(scores):.4f} Â± {np.std(scores):.4f}")
```

---

## ğŸ“ Support

Pour toute question :
1. Consultez le TROUBLESHOOTING.md
2. VÃ©rifiez que la structure des dossiers est correcte
3. VÃ©rifiez que le dataset est au bon endroit

---


**ğŸ‰ PrÃªte pour la Production !**

*DerniÃ¨re mise Ã  jour : Octobre 2025*
*Version : 2.0*
